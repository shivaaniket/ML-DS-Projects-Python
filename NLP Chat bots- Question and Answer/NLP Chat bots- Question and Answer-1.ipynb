{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of the project:\n",
    "The objective is to build a question and answer chat bots on small stories using BaBi data set by Facebook research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activities/Approach:\n",
    "\n",
    "This includesExploring the Format of the Data, Setting up Vocabulary of All Words, Vectorizing the Data,Building RNN and Evaluating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Information:\n",
    "\n",
    "The data set obtained from Babi Data Set from Facebook Research. Also, the train and test data in text format uploaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'?': 1,\n",
       " 'moved': 2,\n",
       " 'office': 3,\n",
       " 'in': 4,\n",
       " 'left': 5,\n",
       " 'down': 6,\n",
       " 'grabbed': 7,\n",
       " 'the': 8,\n",
       " 'apple': 9,\n",
       " 'bathroom': 10,\n",
       " 'there': 11,\n",
       " 'took': 12,\n",
       " 'went': 13,\n",
       " 'discarded': 14,\n",
       " 'back': 15,\n",
       " 'dropped': 16,\n",
       " '.': 17,\n",
       " 'is': 18,\n",
       " 'bedroom': 19,\n",
       " 'milk': 20,\n",
       " 'put': 21,\n",
       " 'yes': 22,\n",
       " 'football': 23,\n",
       " 'journeyed': 24,\n",
       " 'got': 25,\n",
       " 'mary': 26,\n",
       " 'sandra': 27,\n",
       " 'picked': 28,\n",
       " 'daniel': 29,\n",
       " 'no': 30,\n",
       " 'john': 31,\n",
       " 'garden': 32,\n",
       " 'hallway': 33,\n",
       " 'travelled': 34,\n",
       " 'kitchen': 35,\n",
       " 'up': 36,\n",
       " 'to': 37}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  8, 19, 17],\n",
       "       [ 0,  0,  0, ...,  8, 32, 17],\n",
       "       [ 0,  0,  0, ...,  8, 32, 17],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  8,  9, 17],\n",
       "       [ 0,  0,  0, ...,  8, 32, 17],\n",
       "       [ 0,  0,  0, ...,  9, 11, 17]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 31,  4,  8, 35,  1],\n",
       "       [18, 31,  4,  8, 35,  1],\n",
       "       [18, 31,  4,  8, 32,  1],\n",
       "       ...,\n",
       "       [18, 26,  4,  8, 19,  1],\n",
       "       [18, 27,  4,  8, 32,  1],\n",
       "       [18, 26,  4,  8, 32,  1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       497.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       497.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building the Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 6, 156)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_2[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.8637 - acc: 0.5068 - val_loss: 0.6944 - val_acc: 0.5030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.7025 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.5030cc: - ETA: 3s - loss:\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.6956 - acc: 0.5020 - val_loss: 0.6940 - val_acc: 0.4970\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 0.6951 - acc: 0.4958 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 8s 805us/step - loss: 0.6950 - acc: 0.4939 - val_loss: 0.6947 - val_acc: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 8s 816us/step - loss: 0.6941 - acc: 0.5040 - val_loss: 0.6937 - val_acc: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 7s 743us/step - loss: 0.6943 - acc: 0.5039 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 0.6942 - acc: 0.4994 - val_loss: 0.6942 - val_acc: 0.4970\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 0.6945 - acc: 0.4962 - val_loss: 0.6935 - val_acc: 0.5030\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 7s 712us/step - loss: 0.6931 - acc: 0.5165 - val_loss: 0.6912 - val_acc: 0.5310\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 7s 692us/step - loss: 0.6425 - acc: 0.6259 - val_loss: 0.5196 - val_acc: 0.7780\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 7s 681us/step - loss: 0.5054 - acc: 0.7698 - val_loss: 0.4306 - val_acc: 0.8190\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 7s 677us/step - loss: 0.4396 - acc: 0.8149 - val_loss: 0.3997 - val_acc: 0.8300\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.4106 - acc: 0.8287 - val_loss: 0.3908 - val_acc: 0.8320\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 8s 794us/step - loss: 0.3832 - acc: 0.8446 - val_loss: 0.4015 - val_acc: 0.8230\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 7s 726us/step - loss: 0.3720 - acc: 0.8505 - val_loss: 0.3763 - val_acc: 0.8300\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 0.3585 - acc: 0.8535 - val_loss: 0.3749 - val_acc: 0.8370\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 7s 708us/step - loss: 0.3448 - acc: 0.8587 - val_loss: 0.3620 - val_acc: 0.8360\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 8s 822us/step - loss: 0.3375 - acc: 0.8597 - val_loss: 0.3605 - val_acc: 0.8420\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 8s 839us/step - loss: 0.3329 - acc: 0.8608 - val_loss: 0.3956 - val_acc: 0.8340\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 8s 782us/step - loss: 0.3239 - acc: 0.8619 - val_loss: 0.3495 - val_acc: 0.8390- \n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 8s 765us/step - loss: 0.3216 - acc: 0.8620 - val_loss: 0.3448 - val_acc: 0.8310\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 8s 787us/step - loss: 0.3173 - acc: 0.8624 - val_loss: 0.3410 - val_acc: 0.8420\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 8s 810us/step - loss: 0.3143 - acc: 0.8626 - val_loss: 0.3438 - val_acc: 0.8340\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.3152 - acc: 0.8644 - val_loss: 0.3513 - val_acc: 0.8410\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 8s 786us/step - loss: 0.3143 - acc: 0.8659 - val_loss: 0.3404 - val_acc: 0.8380\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 8s 801us/step - loss: 0.3077 - acc: 0.8679 - val_loss: 0.3530 - val_acc: 0.8430\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 7s 687us/step - loss: 0.3041 - acc: 0.8665 - val_loss: 0.3444 - val_acc: 0.8390\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 7s 701us/step - loss: 0.3023 - acc: 0.8655 - val_loss: 0.3636 - val_acc: 0.8290\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.3045 - acc: 0.8676 - val_loss: 0.3404 - val_acc: 0.8470\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.3027 - acc: 0.8671 - val_loss: 0.3480 - val_acc: 0.8400\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.3002 - acc: 0.8683 - val_loss: 0.3431 - val_acc: 0.8390\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.2997 - acc: 0.8682 - val_loss: 0.3401 - val_acc: 0.8370\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 7s 743us/step - loss: 0.2987 - acc: 0.8696 - val_loss: 0.3413 - val_acc: 0.8330\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.2984 - acc: 0.8696 - val_loss: 0.3413 - val_acc: 0.8340\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 7s 700us/step - loss: 0.2987 - acc: 0.8686 - val_loss: 0.3501 - val_acc: 0.8380\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 7s 697us/step - loss: 0.2978 - acc: 0.8699 - val_loss: 0.3324 - val_acc: 0.8490\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 7s 701us/step - loss: 0.3012 - acc: 0.8712 - val_loss: 0.3576 - val_acc: 0.8460\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 7s 719us/step - loss: 0.2948 - acc: 0.8687 - val_loss: 0.3809 - val_acc: 0.8340\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.2957 - acc: 0.8678 - val_loss: 0.3431 - val_acc: 0.8490oss: 0.2956 - acc: 0.867\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 7s 707us/step - loss: 0.2920 - acc: 0.8712 - val_loss: 0.3527 - val_acc: 0.8490\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.2959 - acc: 0.8699 - val_loss: 0.3463 - val_acc: 0.8450\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 7s 704us/step - loss: 0.2947 - acc: 0.8707 - val_loss: 0.3433 - val_acc: 0.8460\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 7s 711us/step - loss: 0.2925 - acc: 0.8707 - val_loss: 0.3712 - val_acc: 0.8560\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 7s 708us/step - loss: 0.2914 - acc: 0.8711 - val_loss: 0.3439 - val_acc: 0.8360\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 7s 690us/step - loss: 0.2905 - acc: 0.8714 - val_loss: 0.3413 - val_acc: 0.8490\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 7s 707us/step - loss: 0.2930 - acc: 0.8727 - val_loss: 0.3441 - val_acc: 0.8490\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 7s 680us/step - loss: 0.2933 - acc: 0.8688 - val_loss: 0.3401 - val_acc: 0.8400\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.2933 - acc: 0.8709 - val_loss: 0.3448 - val_acc: 0.8410\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 7s 686us/step - loss: 0.2911 - acc: 0.8734 - val_loss: 0.3471 - val_acc: 0.8430\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 7s 683us/step - loss: 0.2888 - acc: 0.8729 - val_loss: 0.3686 - val_acc: 0.8450\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 0.2911 - acc: 0.8729 - val_loss: 0.3671 - val_acc: 0.8410\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.2872 - acc: 0.8765 - val_loss: 0.3599 - val_acc: 0.8450\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.2893 - acc: 0.8735 - val_loss: 0.3329 - val_acc: 0.8430\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 7s 691us/step - loss: 0.2884 - acc: 0.8758 - val_loss: 0.3332 - val_acc: 0.8400\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 0.2849 - acc: 0.8765 - val_loss: 0.3468 - val_acc: 0.8430\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.2843 - acc: 0.8754 - val_loss: 0.3348 - val_acc: 0.8440\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.2853 - acc: 0.8795 - val_loss: 0.3416 - val_acc: 0.8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.2872 - acc: 0.8739 - val_loss: 0.3423 - val_acc: 0.8470\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.2807 - acc: 0.8779 - val_loss: 0.3743 - val_acc: 0.8260\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 7s 728us/step - loss: 0.2823 - acc: 0.8777 - val_loss: 0.3504 - val_acc: 0.8430\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 7s 730us/step - loss: 0.2834 - acc: 0.8796 - val_loss: 0.3471 - val_acc: 0.8450\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.2809 - acc: 0.8802 - val_loss: 0.3359 - val_acc: 0.8470\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.2767 - acc: 0.8809- ETA: 1 - 7s 729us/step - loss: 0.2766 - acc: 0.8810 - val_loss: 0.3499 - val_acc: 0.8450\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.2791 - acc: 0.8804 - val_loss: 0.3474 - val_acc: 0.8500\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 7s 725us/step - loss: 0.2793 - acc: 0.8817 - val_loss: 0.3604 - val_acc: 0.8420\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 7s 713us/step - loss: 0.2745 - acc: 0.8837 - val_loss: 0.3595 - val_acc: 0.8510\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.2723 - acc: 0.8846 - val_loss: 0.3520 - val_acc: 0.8500\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.2681 - acc: 0.8857 - val_loss: 0.3355 - val_acc: 0.8540\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 7s 716us/step - loss: 0.2670 - acc: 0.8837 - val_loss: 0.3393 - val_acc: 0.8450\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 0.2703 - acc: 0.8869 - val_loss: 0.3506 - val_acc: 0.8540\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.2632 - acc: 0.8905 - val_loss: 0.3949 - val_acc: 0.8410\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 8s 818us/step - loss: 0.2637 - acc: 0.8923 - val_loss: 0.3414 - val_acc: 0.8570\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.2584 - acc: 0.8915 - val_loss: 0.3460 - val_acc: 0.8620\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.2580 - acc: 0.8925 - val_loss: 0.3323 - val_acc: 0.8670\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 7s 720us/step - loss: 0.2465 - acc: 0.8997 - val_loss: 0.3669 - val_acc: 0.8550\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 8s 802us/step - loss: 0.2436 - acc: 0.9014 - val_loss: 0.3356 - val_acc: 0.8580\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 8s 838us/step - loss: 0.2311 - acc: 0.9077 - val_loss: 0.3306 - val_acc: 0.8720\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 0.2259 - acc: 0.9048 - val_loss: 0.2945 - val_acc: 0.8690\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.2135 - acc: 0.9115 - val_loss: 0.2812 - val_acc: 0.8740\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 7s 711us/step - loss: 0.2102 - acc: 0.9092 - val_loss: 0.2969 - val_acc: 0.8690\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 7s 697us/step - loss: 0.1958 - acc: 0.9150 - val_loss: 0.2833 - val_acc: 0.8700\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 7s 722us/step - loss: 0.1858 - acc: 0.9228 - val_loss: 0.2846 - val_acc: 0.8760\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 9s 870us/step - loss: 0.1791 - acc: 0.9235 - val_loss: 0.2600 - val_acc: 0.8820\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 7s 735us/step - loss: 0.1651 - acc: 0.9297 - val_loss: 0.2420 - val_acc: 0.8920\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 0.1684 - acc: 0.9330 - val_loss: 0.2512 - val_acc: 0.8930\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 8s 759us/step - loss: 0.1618 - acc: 0.9337 - val_loss: 0.2319 - val_acc: 0.8910\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 8s 833us/step - loss: 0.1570 - acc: 0.9393 - val_loss: 0.2307 - val_acc: 0.9010\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 8s 753us/step - loss: 0.1552 - acc: 0.9382 - val_loss: 0.2396 - val_acc: 0.8970\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 8s 821us/step - loss: 0.1508 - acc: 0.9377 - val_loss: 0.2403 - val_acc: 0.8980\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 0.1452 - acc: 0.9395 - val_loss: 0.2447 - val_acc: 0.90501452 - acc: 0.93\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 8s 767us/step - loss: 0.1463 - acc: 0.9435 - val_loss: 0.2329 - val_acc: 0.9130\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 7s 704us/step - loss: 0.1417 - acc: 0.9397 - val_loss: 0.2467 - val_acc: 0.9150\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.1388 - acc: 0.9442 - val_loss: 0.2258 - val_acc: 0.9090\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 7s 717us/step - loss: 0.1344 - acc: 0.9458 - val_loss: 0.2456 - val_acc: 0.9080\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 8s 774us/step - loss: 0.1386 - acc: 0.9443 - val_loss: 0.2473 - val_acc: 0.9100\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 8s 793us/step - loss: 0.1300 - acc: 0.9466 - val_loss: 0.2479 - val_acc: 0.9060\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 8s 773us/step - loss: 0.1237 - acc: 0.9491 - val_loss: 0.2486 - val_acc: 0.9140\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 8s 770us/step - loss: 0.1187 - acc: 0.9526 - val_loss: 0.2457 - val_acc: 0.9060\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 0.1234 - acc: 0.9534 - val_loss: 0.2349 - val_acc: 0.9050- loss: 0\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.1156 - acc: 0.9531 - val_loss: 0.2506 - val_acc: 0.9110\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 7s 702us/step - loss: 0.1134 - acc: 0.9544 - val_loss: 0.2275 - val_acc: 0.9140\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 0.1114 - acc: 0.9575 - val_loss: 0.2428 - val_acc: 0.9100\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 7s 662us/step - loss: 0.1117 - acc: 0.9563 - val_loss: 0.2545 - val_acc: 0.9100\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 7s 680us/step - loss: 0.1064 - acc: 0.9567 - val_loss: 0.2466 - val_acc: 0.9130\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 7s 684us/step - loss: 0.1050 - acc: 0.9596 - val_loss: 0.2389 - val_acc: 0.9080\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 0.0981 - acc: 0.9614 - val_loss: 0.2298 - val_acc: 0.9150\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.1030 - acc: 0.9587 - val_loss: 0.2503 - val_acc: 0.9230\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 0.0994 - acc: 0.9613 - val_loss: 0.2172 - val_acc: 0.9160\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 0.1000 - acc: 0.9622 - val_loss: 0.2494 - val_acc: 0.9150\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.0968 - acc: 0.9638 - val_loss: 0.2389 - val_acc: 0.9230\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 6s 648us/step - loss: 0.0935 - acc: 0.9638 - val_loss: 0.2314 - val_acc: 0.9230\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 7s 650us/step - loss: 0.0872 - acc: 0.9670 - val_loss: 0.2475 - val_acc: 0.9170\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 0.0885 - acc: 0.9669 - val_loss: 0.2245 - val_acc: 0.9240\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 0.0935 - acc: 0.9666 - val_loss: 0.2486 - val_acc: 0.9240\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 7s 659us/step - loss: 0.0812 - acc: 0.9682 - val_loss: 0.2457 - val_acc: 0.9210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 7s 730us/step - loss: 0.0934 - acc: 0.9660 - val_loss: 0.2280 - val_acc: 0.9200\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 7s 724us/step - loss: 0.0836 - acc: 0.9690 - val_loss: 0.2358 - val_acc: 0.9240\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 7s 708us/step - loss: 0.0816 - acc: 0.9704 - val_loss: 0.2271 - val_acc: 0.9280\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 7s 709us/step - loss: 0.0810 - acc: 0.9715 - val_loss: 0.2147 - val_acc: 0.9260\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99999976\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing  Own Stories and Questions\n",
    "\n",
    "Only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99299604\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
